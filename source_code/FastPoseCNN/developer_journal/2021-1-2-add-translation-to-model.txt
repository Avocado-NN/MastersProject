AFTER 2021-1-2-pw_qloss_constant_1.txt

Problem:
Need to add the decoder that handles translation (xyz) and include all additional
components in the training loop to allow the training of these features.

Solution:


Information:

--------------------------------------------------------------------------------
Daily Entries
1/2/2021

Added the decoder branches and heads for both 'xy' and 'z' pixel-wise features.
All necessary code, such as changing `class_compress_quaternion` to 
`class_compress` to accomodate for all types of data was a success. I also expanded
the function `dense_class_data_aggregation` to account for the new entries. Also 
expanded the function `find_matches_batched` to account for the new entries.

With the addition of all the pytorch tensor intensive code, the training loop is 
still functional. Pushing as training is stable. Plan on making visualization for
the new regressed features. Afterwards, will look into difference loss functions 
and data augmentations (such as log(z/1000) to make it easier for regression 
stability).

git pushed: added xy and z components to the model and training loop.

While trying to implement the visualization, I encountered this strange error:

Traceback (most recent call last):
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 521, in train
    self.train_loop.run_training_epoch()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 560, in run_training_epoch
    batch_output = self.run_training_batch(batch, batch_idx, dataloader_idx)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 718, in run_training_batch
    self.optimizer_step(optimizer, opt_idx, batch_idx, train_step_and_backward_closure)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 493, in optimizer_step
    model_ref.optimizer_step(
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1258, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 278, in step
    self.__optimizer_step(*args, closure=closure, profiler_name=profiler_name, **kwargs)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 136, in __optimizer_step
    optimizer.step(closure=closure, *args, **kwargs)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/catalyst/contrib/nn/optimizers/lookahead.py", line 61, in step
    loss = self.optimizer.step(closure)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/catalyst/contrib/nn/optimizers/radam.py", line 55, in step
    loss = closure()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 708, in train_step_and_backward_closure
    result = self.training_step_and_backward(
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 806, in training_step_and_backward
    result = self.training_step(split_batch, batch_idx, opt_idx, hiddens)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 330, in training_step
    training_step_output = self.trainer.accelerator_backend.training_step(args)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py", line 83, in training_step
    return self._step(self.trainer.model.training_step, args)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py", line 78, in _step
    output = model_step(*args)
  File "train.py", line 125, in training_step
    multi_task_losses, multi_task_metrics = self.shared_step('train', batch, batch_idx)
  File "train.py", line 205, in shared_step
    losses, metrics = self.loss_function(
  File "train.py", line 237, in loss_function
    losses[loss_name] = loss_attrs['F'](outputs, inputs)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/students/edavalos/GitHub/FastPoseCNN/source_code/FastPoseCNN/lib/loss.py", line 103, in forward
    return torch.tensor([1], device=cat_mask.device, requires_grad=True)
RuntimeError: Only Tensors of floating point and complex dtype can require gradients

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train.py", line 611, in <module>
    trainer.fit(
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 470, in fit
    results = self.accelerator_backend.train()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py", line 68, in train
    results = self.train_or_test()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 69, in train_or_test
    results = self.trainer.train()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 552, in train
    self.train_loop.on_train_end()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 191, in on_train_end
    self.check_checkpoint_callback(should_save=True, is_last=True)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 225, in check_checkpoint_callback
    callback.on_validation_end(self.trainer, model)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 203, in on_validation_end
    self.save_checkpoint(trainer, pl_module)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 248, in save_checkpoint
    self._save_top_k_checkpoints(trainer, pl_module, monitor_candidates)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 590, in _save_top_k_checkpoints
    self._update_best_and_save(current, epoch, step, trainer, pl_module, metrics)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 619, in _update_best_and_save
    filepath = self._get_metric_interpolated_filepath_name(ckpt_name_metrics, epoch, step, del_filepath)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 523, in _get_metric_interpolated_filepath_name
    filepath = self.format_checkpoint_name(epoch, step, ckpt_name_metrics)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 439, in format_checkpoint_name
    filename = self._format_checkpoint_name(
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 407, in _format_checkpoint_name
    filename = filename.format(**metrics)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/torch/tensor.py", line 535, in __format__
    return object.__format__(self, format_spec)
TypeError: unsupported format string passed to Tensor.__format__

Simply removed the requires_grad component and ran again.

Now encountering a difference issue:

Traceback (most recent call last):
  File "train.py", line 611, in <module>
    trainer.fit(
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 470, in fit
    results = self.accelerator_backend.train()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py", line 68, in train
    results = self.train_or_test()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 69, in train_or_test
    results = self.trainer.train()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 521, in train
    self.train_loop.run_training_epoch()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 588, in run_training_epoch
    self.trainer.run_evaluation(test_mode=False)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 625, in run_evaluation
    self.evaluation_loop.on_evaluation_epoch_end()
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py", line 334, in on_evaluation_epoch_end
    self.trainer.call_hook('on_validation_epoch_end', *args, **kwargs)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 887, in call_hook
    trainer_hook(*args, **kwargs)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py", line 87, in on_validation_epoch_end
    callback.on_validation_epoch_end(self, self.get_model())
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py", line 39, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/students/edavalos/GitHub/FastPoseCNN/source_code/FastPoseCNN/callbacks.py", line 69, in on_validation_epoch_end
    self.shared_epoch_end('valid', trainer, pl_module)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py", line 39, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/students/edavalos/GitHub/FastPoseCNN/source_code/FastPoseCNN/callbacks.py", line 128, in shared_epoch_end
    self.log_epoch_average(mode, trainer, pl_module)
  File "/home/students/edavalos/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py", line 39, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/students/edavalos/GitHub/FastPoseCNN/source_code/FastPoseCNN/callbacks.py", line 167, in log_epoch_average
    average = torch.mean(torch.stack(cuda_0_log))
RuntimeError: stack expects each tensor to be equal size, but got [] at entry 0 and [1] at entry 1

Simply had to change torch.tensor([1]) to torch.tensor(1). After doing this, the
training loop was successful. I was able to run tensorboard and see the visualization
of the new task. xy task is doing well as I can see given a small run, but z is
looking terrible. The error is extremely high and the visualization results in a 
completely white image. Need to check this out.

Fixed the z visualization problem. The value in the image was for a [0,255] image
format. However, the dtype of the image was float32, therefore matplotlib interpreted
that the image should have a range of [0,1], resulting in a completely white image
since most values were greater than 1.

Overall, the visualization of xy and z are looking good. My only concern is that
the loss of 'z' is too large. This is probably since it has large values. Simply
just applying np.log is enough. I placed the np.log in data_manipulation.py within
the `create_simple_dense_3d_centers` method, line 353. Note this when reconstructing
the pose later.

After implementing np.log(z), the magnitude of the loss for 'z' reduced by a order 
of 4, which is great. Now I plan on git pushing and then running a long test.

git pushed: "completed xy and z visualization and improved stability of z by doing 
np.log(z)."